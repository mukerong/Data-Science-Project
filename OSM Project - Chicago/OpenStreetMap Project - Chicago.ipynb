{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Project - Chicago\n",
    "\n",
    "This project will use the map of a beautiful city, Chicago, IL, United States. I have lived here since graduating from college. I am very interested to see what the map database reveals. After unziping, the total database is a little more than 2GB.\n",
    "\n",
    "I will analyze this dataset by doing the following:\n",
    "\n",
    "* Extract a sample from the database.\n",
    "* Find the problems encountered in this dataset. \n",
    "* Clean up the data and import them to SQL.\n",
    "* Explore the data by querying in SQLite.\n",
    "* Additional ideas I have after exploring the dataset.\n",
    "\n",
    "Reference:\n",
    "\n",
    "* The summary of Chicago area can be found at [OpenStreetMap website](https://www.openstreetmap.org/relation/122604). \n",
    "* This data can be downloaded at [Mapzen Metro Extracts](https://mapzen.com/data/metro-extracts/metro/chicago_illinois/). \n",
    "* [OpenStreetMap Wiki](https://wiki.openstreetmap.org/wiki/Main_Page) shows the detail explanation of OpenStreetMap database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, this database is quite large, more than 2GB. Directly opening it or parsing it will crash the computer. Therefore, it is a good idea to extract a sample from this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all analysis, everything starts from importing the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import lxml\n",
    "import cerberus\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will write a function to find element I want from the original .osm file, and write into a sample osm file.\n",
    "After reading through the wiki, I think the most important tag for this dataset are \"node\", \"way\", and \"relation\" tag. Therefore, the function will focus on getting the elements from these three tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "osm_file = 'chicago_illinois.osm'\n",
    "sample_file = 'sample_chicago.osm'\n",
    "\n",
    "tag = ['node', 'way', 'relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_element(osm_file, tags = ('node', 'way', 'relation')):\n",
    "    '''\n",
    "    This function will read through an XML file, get the element from desired tags.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    osm_file: .xml or .osm file\n",
    "        the XML or OSM file to be parsed\n",
    "    \n",
    "    tags: string or list\n",
    "        the tag name that you want to get elements from. \n",
    "        default is ['node', 'way', 'relation']\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    .xml or .osm file\n",
    "    '''\n",
    "    \n",
    "    context = iter(ET.iterparse(osm_file, events = ('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    \n",
    "    for event, elem in context:\n",
    "        if (event == 'end') and (elem.tag in tags):\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generate the elements, it is time to write it into another file.\n",
    "\n",
    "k is a parameter. It defines the one element to export for every k elements. The bigger the k is, the smaller the sample will be. Since the data is big, I choose to use 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1000\n",
    "    \n",
    "with open(sample_file, 'wb') as output:\n",
    "    output.write(bytes('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n', 'UTF-8'))\n",
    "    output.write(bytes('<osm>\\n  ', 'UTF-8'))\n",
    "\n",
    "    for i, element in enumerate(get_element(osm_file)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write(bytes('</osm>', 'UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the sample from the database, it is a good idea to see the big picture of this sample to see if we have had enough data within the sample. Therefore, I want to write a function to check what tags are in the sample dataset, and how many of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tag(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        tag = elem.tag\n",
    "        if tag not in tags:\n",
    "            tags[tag] = 1\n",
    "        else:\n",
    "            tags[tag] += 1\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'member': 69,\n",
       " 'nd': 10728,\n",
       " 'node': 8718,\n",
       " 'osm': 1,\n",
       " 'relation': 5,\n",
       " 'tag': 6761,\n",
       " 'way': 1233}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tag(sample_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be that we have a good amount of data within the sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem in this dataset\n",
    "\n",
    "After getting the sample data, we can look through the dataset, find the problems and clean it up.\n",
    "\n",
    "Through reading the documente and look through the sample data in a text editor, `<tag>` is used to save all the values. \n",
    "\n",
    "Here are some problems I noticed the following potential problems through reading the data:\n",
    "\n",
    "* The `<tag>`'s k attribute value is not consistent. Some only have lower case like \"ele\". Some have both lower case and colon, like \"gnis: id\". Others have special characters like.\n",
    "* The street name is not consistent. Some uses the whole spell, like \"street\" and \"avenue\", while others use abbreviation, like \"St\" and \"St.\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k attribute issue\n",
    "\n",
    "I will use regular expression to find the pattern that mentioned above. Later, I will define a function to count each pattern in the sample file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def key_type(filename, keys):\n",
    "    \n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag == 'tag':\n",
    "            key = element.get('k')\n",
    "            if lower.search(key):\n",
    "                keys['lower'] += 1\n",
    "            elif re.findall(lower_colon, key):\n",
    "                keys['lower_colon'] += 1\n",
    "            elif re.findall(problemchars, key):\n",
    "                keys['problemchars'] += 1\n",
    "            else:\n",
    "                keys['other'] += 1\n",
    "        \n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 2016, 'lower_colon': 3135, 'other': 1610, 'problemchars': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_type(sample_file, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street name issue\n",
    "\n",
    "Similar to k attribute, I will use regular expression to find the pattern. I will build up a list showing the expected value, and printed street type not in the expected list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    match = street_type_re.search(street_name)\n",
    "    if match:\n",
    "        street_type = match.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "    pprint.pprint(dict(street_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit(filename):\n",
    "    street_types = defaultdict(set)\n",
    "    \n",
    "    for event, elem in ET.iterparse(filename, events=(\"start\",)): \n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                print(tag['k'])\n",
    "                break\n",
    "                if tag['k'] == 'addr:street':\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "element indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-670fbf896074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-65a2f656add4>\u001b[0m in \u001b[0;36maudit\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"node\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"way\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'addr:street'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: element indices must be integers"
     ]
    }
   ],
   "source": [
    "audit(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": 'Avenue',\n",
    "            'Rd.': 'Road'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    \n",
    "    update_name = name.split(' ')[-1]\n",
    "    if update_name in mapping:\n",
    "        new_name = mapping[update_name]\n",
    "        print(new_name)\n",
    "\n",
    "        name = name.replace(update_name, new_name)\n",
    "\n",
    "    return name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
